{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CA02_ naive_bayes_Xinyu Zhou.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sophia-zxy/CA03/blob/main/CA02__naive_bayes_Xinyu_Zhou.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6Dq_2BLoD_c"
      },
      "source": [
        "# Your name: <Xinyu Zhou> Xinyu Zhou\r\n",
        "## Assignment Name: CA02 - naive_bayes\r\n",
        "### Colab Link:https://colab.research.google.com/drive/1pK5h52scE9_AazSL71mnd8Cc9YhdI1Bj?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCZYXwtCsL_y"
      },
      "source": [
        "This is a eMail Spam Classifers that uses Naive Bayes supervised machine learning algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "4p_DvtT7sOIr"
      },
      "source": [
        "#os module is imported\n",
        "import os\n",
        "\n",
        "#import numpy-a general-purpose array-processing package\n",
        "import numpy as np\n",
        "\n",
        "# import counter class from collections module to Counter Class object\n",
        "from collections import Counter\n",
        "\n",
        "# naive bayes classification\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Classification, accuracy\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXknSIrLvzfQ"
      },
      "source": [
        "This function builds a Dictionary of most common 3000 words from all the email content. First it adds all words and symbols in the dictionary. Then it removes all non-alpha-numeric characters and any single character alpha-numeric characters. After this is complete it shrinks the Dictionary by keeping only most common 3000 words in the dictionary. It returns the Dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAP8g7kKaT0m"
      },
      "source": [
        "#os.path.join() method in Python join one or more path components intelligently\r\n",
        "#The open() function opens a file, and returns it as a file object,  With- automatically close the file handler when you are done with it\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "jjKF0nIMwz8_"
      },
      "source": [
        "def make_Dictionary(root_dir):\n",
        "  all_words = [] # create a empty list\n",
        "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)] #list comprehension to iterate root path get all files \n",
        "  for mail in emails:      # iterate each files and split each word\n",
        "    with open(mail) as m:\n",
        "      for line in m:\n",
        "        words = line.split()\n",
        "        all_words += words\n",
        "  dictionary = Counter(all_words) # get each single letter in each word\n",
        "  list_to_remove = list(dictionary) #create list of all letters\n",
        "\n",
        "  for item in list_to_remove: #iterate each letter, check it is alpha or not\n",
        "    if item.isalpha() == False:\n",
        "      del dictionary[item]    # not alpha, delete\n",
        "    elif len(item) == 1:      # is symbol, delete\n",
        "      del dictionary[item]\n",
        "  dictionary = dictionary.most_common(3000) #get most common letters\n",
        "  return dictionary\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_NG2-TpxQ1j"
      },
      "source": [
        "This function extracts feature columns and populates their values (Feature Matrix of 3000 comumns and rows equal to the number of email files). The function also analyzes the File Names of each email file and decides if it's a Spam or not based on the naming convention. Based on this the function also creates the Labelled Data Column. This function is used to extract the training dataset as well as the testing dataset and returns the Feature Dataset and the Label column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DpEDOm5bXLc"
      },
      "source": [
        "#np.zeros()  returns a new array of given shape and type, with zeros.\r\n",
        "#enumerate() starts counting from this number."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "dmVW5xNlyOFc"
      },
      "source": [
        "def extract_features(mail_dir):\n",
        "  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
        "  features_matrix = np.zeros((len(files),3000)) # generate a label and word frequency matrix, len(files) rows, 3000 columns\n",
        "  train_labels = np.zeros(len(files))          # create train set\n",
        "  count = 1;\n",
        "  docID = 0;\n",
        "  for fil in files:                             #iterate each file in files list\n",
        "    with open(fil) as fi:                       #open each file\n",
        "      for i, line in enumerate(fi):             #iterate each line in a file\n",
        "        if i ==2:                               #Body of email is only 3rd line of text file\n",
        "          words = line.split()                  #Line2, split each word in a line\n",
        "          for word in words:                    #iterate each letter in a word\n",
        "            wordID = 0\n",
        "            for i, d in enumerate(dictionary):  #iterate each word\n",
        "              if d[0] == word:                  # compare common word or not\n",
        "                wordID = i\n",
        "                features_matrix[docID,wordID] = words.count(word) \n",
        "      train_labels[docID] = 0;\n",
        "      filepathTokens = fil.split('/')           \n",
        "      lastToken = filepathTokens[len(filepathTokens)-1]\n",
        "      if lastToken.startswith(\"spmsg\"):\n",
        "        train_labels[docID] = 1;\n",
        "        count = count + 1\n",
        "      docID = docID + 1\n",
        "  return features_matrix, train_labels                "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbOV1Y4hxpiy"
      },
      "source": [
        "The section is the main Program that calls the above two functions and gets executed first. First it \"trains\" the model using model.fit function and Training Dataset. After that it scores the Test Data set by running the Trained Model with the Test Data set. At the end it prints the model performance in terms of accuracy score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khaJPpUTAsmI",
        "outputId": "92c54fab-fc2a-4f67-d690-ac66a5394b60"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "zoq-rE7Mx0pp"
      },
      "source": [
        "TRAIN_DIR = '/content/drive/My Drive/MSBA_Colab_2020/ML_Algorithms/CA02/Data/train-mails'\n",
        "TEST_DIR = '/content/drive/My Drive/MSBA_Colab_2020/ML_Algorithms/CA02/Data/test-mails'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "134lmhauyQxE",
        "outputId": "da58b4b5-3a25-42eb-b195-41edaea5f10a"
      },
      "source": [
        "dictionary = make_Dictionary(TRAIN_DIR)\n",
        "\n",
        "print (\"reading and processing emails from TRAIN and TEST folders\")\n",
        "features_matrix, labels = extract_features(TRAIN_DIR)\n",
        "test_features_matrix, test_labels = extract_features(TEST_DIR)\n",
        "\n",
        "model = GaussianNB() #assumes that features follow a normal distribution. Create a Gaussian Classifier\n",
        "print (\"Training Model using Gaussian Naibe Bayes algorithm .....\")\n",
        "\n",
        "model.fit(features_matrix, labels)                                      #train model\n",
        "print (\"Training completed\")\n",
        "print (\"testing trained model to predict Test Data labels\")\n",
        "\n",
        "predicted_labels = model.predict(test_features_matrix)\n",
        "print (\"Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\")\n",
        "print (accuracy_score(test_labels, predicted_labels))                   # accuracy score,predict output "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reading and processing emails from TRAIN and TEST folders\n",
            "Training Model using Gaussian Naibe Bayes algorithm .....\n",
            "Training completed\n",
            "testing trained model to predict Test Data labels\n",
            "Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
            "0.9653846153846154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5_mPrvN586A"
      },
      "source": [
        "======================= END OF PROGRAM ========================="
      ]
    }
  ]
}